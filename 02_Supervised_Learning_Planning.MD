# 02 - Supervised Learning: Predicting Next Jewelry Purchase

## 項目目標
根據客戶的購買歷史，建立一個模型預測該客戶在下一次購物時是否會購買珠寶商品。

## 整體規劃與任務分解

### 任務 1: 數據結構探索與理解
- **目標**: 理解三個表的關係及數據分佈
- **具體工作**:
  - 載入並檢查 `customers.csv` (客戶年齡、ID等基本訊息)
  - 載入並檢查 `articles.csv` (商品類型、編號等特徵)
  - 載入並檢查 `transactions_train_sample.csv` (購買記錄：客戶ID、商品ID、購買日期等)
  - 統計珠寶商品數量、購買珠寶的客戶數量、購買紀錄分佈

### 任務 2: 特徵工程策略設計
建立機器學習模型時，我們需要從原始數據中提取特徵(covariates)：

**客戶級特徵 (Customer Features)**:
- 過去購買珠寶商品的次數
- 過去購買珠寶商品的總金額
- 平均訂單價值
- 上次購買珠寶至今的天數 (recency)
- 客戶年齡或年齡分組
- 購買頻率 (多久購買一次)

**商品級特徵 (Product Features)**:
- 商品是否為珠寶 (yes/no, 二元)
- 商品類別 (necklace, bracelet, earring, ring 等)
- 商品受歡迎程度 (過去購買的客戶數)
- 商品平均價格

**交互特徵 (Interaction Features)**:
- 客戶是否曾購買該特定商品類別
- 客戶過去購買該商品類別的次數

### 任務 3: 反應變數與數據集設計

**反應變數 (Response Variable) - 購買 vs 不購買**:
- 方法: 對每個客戶的購買歷史按時間順序分割
  - 第一部分 (過去購買紀錄) → 用於提取客戶特徵
  - 第二部分 (最後一次購買) → 用於確定是否購買珠寶 (target: 0 或 1)

**數據集設計**:
1. 對每個客戶的最後一次購買作為一個樣本
2. 基於該客戶在此日期前的購買歷史計算特徵
3. 標籤: 該次購買是否為珠寶 (1 = 珠寶, 0 = 非珠寶)

**為什麼這種方法好**:
- 充分利用時間序列信息
- 確保數據泄露不會發生 (特徵來自過去，預測未來)
- 實際可應用: 可用於推薦系統

### 任務 4: 如何處理非珠寶購買客戶 

**理解問題**:
非珠寶購買者提供了"反面示例" - 他們購買的不是珠寶。這些數據很寶貴！

**三種策略**:

**策略A: 平衡數據集** (最簡單，推薦初學者)
```
假設有 1000 個珠寶購買者，3000 個非珠寶購買者
→ 隨機抽取 1000 個非珠寶購買者
→ 最終: 1000 珠寶 + 1000 非珠寶 = 2000 個樣本 (50-50 平衡)
好處: 模型不會被多數類(非珠寶)主導，學習也更公平
```

**策略B: 分層抽樣** (進階)
```
按客戶特徵分層 (例如年齡群組)
每層內部做平衡
保留各年齡群組的分佈特性
```

**策略C: 加權損失函數** (高級, 不需要刪除數據)
```
在模型訓練時給予少數類(珠寶購買者)更高的權重
模型會更努力學習預測珠寶購買
在本項目中暫不使用，但未來可升級到此方法
```

### 任務 5: 模型漸進式開發策略

**第一層: 簡單基準模型** (Baseline)
1. 邏輯斯蒂迴歸 (Logistic Regression)
   - 線性模型，易於理解和解釋
   - 快速建立基準，了解特徵重要性
2. 評估指標: 準確度(Accuracy)、精準度(Precision)、召回率(Recall)、AUC-ROC

**第二層: 樹型模型**
1. 決策樹 (Decision Tree)
   - 能自動捕捉非線性關係
   - 易於可視化決策過程
2. 隨機森林 (Random Forest)
   - 多個決策樹組合
   - 通常比單個樹更穩定和準確
3. 評估: 與基準模型對比

**第三層: Advanced Ensemble & Deep Learning Models** (如果性能還需改進)

1. **Gradient Boosting Machines** (梯度提升機)
   - XGBoost, LightGBM: 當前業界最強力的方法之一
   - 自動特徵交互與非線性捕捉
   - 需要更多超參數調整
   
2. **Deep Neural Networks (DNN)** (深度神經網絡 - 簡單設計)
   - 入門級 DNN: 2-3 層隱層，每層 64-128 個神經元
   - 激活函數: ReLU (簡單且效果好)
   - 使用 Dropout 防止過度擬合 (dropout rate: 0.2-0.3)
   - 輸出層: Sigmoid (二元分類)
   - 為什麼簡單 DNN 值得嘗試:
     * 能捕捉複雜的非線性模式
     * 如果特徵工程好，DNN 可能超越傳統樹型模型
     * TensorFlow/Keras 框架簡單易用，建置只需 10 行代碼
   - 何時使用: 當樹型模型效能達到瓶頸時 (e.g., validation AUC > 0.85 但仍想改進)

