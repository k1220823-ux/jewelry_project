{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7eb8e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Efficiently sample 10% of a large CSV without loading into memory\n",
    "# Adjust input/output paths as needed. This streams line-by-line.\n",
    "! LC_ALL=C awk 'BEGIN{srand();} NR==1{print; next} { if (rand() <= 0.1) print }' data/transactions_train.csv > 'data/transactions_train_sample (10%).csv'\n",
    "# This is a shell command that uses awk to sample 10% of the data without loading it all into memory.\n",
    "# Usage: Run this in a Jupyter cell by prefixing with `!` or execute in the terminal, e.g., `!LC_ALL=C awk ...`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1837c2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f8a0367",
   "metadata": {},
   "source": [
    "# 01 - Data Preprocessing\n",
    "\n",
    "This notebook refactors the large `JewelryDataPreprocessor` class into small, focused functions so it's easier to read and present in a Jupyter Book or on GitHub. Use each cell interactively to explain and run parts of the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fff3a1",
   "metadata": {},
   "source": [
    "## Notebook structure\n",
    "- Imports\n",
    "- Load data helper\n",
    "- Quick inspection\n",
    "- Cleaning helpers (columns, missing values, types)\n",
    "- Feature engineering\n",
    "- Pipeline wrapper and example usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "83fc0e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd  # 導入 pandas，用於資料操作\n",
    "import numpy as np  # 導入 numpy，用於數值運算\n",
    "from pathlib import Path  # 用於處理檔案路徑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "77f28a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_csv(path, **kwargs):  # 載入 CSV 的輕量包裝函式，回傳 DataFrame\n",
    "    \"\"\"Load a CSV into a DataFrame. Returns DataFrame.\n",
    "    Keeps a thin wrapper so we can set defaults and handle common encodings.\n",
    "    \"\"\"\n",
    "    path = Path(path)  # 將路徑轉為 Path 物件，方便後續操作\n",
    "    if not path.exists():  # 若檔案不存在，拋出錯誤提醒\n",
    "        raise FileNotFoundError(f'File not found: {path}')\n",
    "    return pd.read_csv(path, **kwargs)  # 使用 pandas 讀取 CSV，支援傳入額外參數"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3e51f08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preview(df, n=5):  # 簡單顯示資料形狀與前幾列，方便快速檢查\n",
    "    \"\"\"Display basic info and top rows for quick inspection.\n",
    "    Returns nothing; print summary.\n",
    "    \"\"\"\n",
    "    print('Shape:', df.shape)  # 顯示 (rows, columns)\n",
    "    print('\\nColumn types:')  # 顯示欄位型別的前 20 個\n",
    "    print(df.dtypes.head(20))\n",
    "    display(df.head(n))  # 顯示前 n 列作為預覽"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68942f92",
   "metadata": {},
   "source": [
    "### Column cleanup helper\n",
    "Small helpers to standardize column names and drop obviously useless columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bef996fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_column_names(df, lower=True, strip=True, replace_spaces='_'):  # 標準化欄位名稱\n",
    "    cols = list(df.columns)  # 原欄位清單\n",
    "    new_cols = []  # 建立新的欄位名稱清單\n",
    "    for c in cols:\n",
    "        nc = c\n",
    "        if lower:\n",
    "            nc = nc.lower()  # 轉為小寫\n",
    "        if strip:\n",
    "            nc = nc.strip()  # 去除前後空白\n",
    "        if replace_spaces is not None:\n",
    "            nc = nc.replace(' ', replace_spaces)  # 將空白改為底線或指定字元\n",
    "        new_cols.append(nc)\n",
    "    df.columns = new_cols  # 套用新的欄位名稱\n",
    "    return df\n",
    "\n",
    "def drop_columns(df, cols):  # 刪除不需要的欄位（安全檢查只有存在才刪）\n",
    "    cols = [c for c in cols if c in df.columns]  # 只保留存在於 DataFrame 的欄位\n",
    "    return df.drop(columns=cols)  # 回傳刪除後的 DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7be1f4",
   "metadata": {},
   "source": [
    "### Missing values and type conversion\n",
    "Helpers to fill or drop missing values and convert columns to appropriate types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4241a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_missing(df, strategy=None, value=None, cols=None):  # 處理遺失值的通用函式\n",
    "    \"\"\"Fill missing values.\n",
    "    - If `strategy` is 'median' or 'mean', uses numeric column aggregation per-col.\n",
    "    - If `value` is provided, uses that for all selected cols.\n",
    "    \"\"\"\n",
    "    if cols is None:\n",
    "        cols = df.columns.tolist()  # 預設處理所有欄位\n",
    "    if strategy in ('median','mean'):\n",
    "        for c in cols:\n",
    "            if pd.api.types.is_numeric_dtype(df[c]):\n",
    "                agg = getattr(df[c].median if strategy=='median' else df[c].mean, '__call__')()  # 計算中位數或平均數\n",
    "                df[c] = df[c].fillna(agg)  # 用聚合值填補遺失值\n",
    "    elif value is not None:\n",
    "        df[cols] = df[cols].fillna(value)  # 使用指定常數填補\n",
    "    else:\n",
    "        df = df.dropna(subset=cols)  # 若無策略則直接移除缺失值列\n",
    "    return df\n",
    "\n",
    "def convert_types(df, conversions):  # 轉換欄位型別，`conversions` 為字典\n",
    "    \"\"\"Convert column types using a dict `conversions`, e.g. {'date_col':'datetime64', 'id':'int'}\n",
    "    \"\"\"\n",
    "    for c, t in conversions.items():\n",
    "        if c not in df.columns:\n",
    "            continue  # 若欄位不存在則跳過\n",
    "        try:\n",
    "            if t == 'datetime':\n",
    "                df[c] = pd.to_datetime(df[c], errors='coerce')  # 轉為 datetime，失敗會變成 NaT\n",
    "            else:\n",
    "                df[c] = df[c].astype(t)  # 嘗試使用 pandas astype 轉換\n",
    "        except Exception as e:\n",
    "            print(f'Could not convert {c} to {t}:', e)  # 若失敗則顯示錯誤\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8edf00b",
   "metadata": {},
   "source": [
    "### Feature engineering\n",
    "Keep this focused and small; add functions as needed for your analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "acecfc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_datetime_parts(df, date_col, drop=True):  # 從日期欄位拆出年/月/日\n",
    "    df = df.copy()  # 複製避免修改原始 DataFrame\n",
    "    if date_col not in df.columns:\n",
    "        raise KeyError(date_col)  # 欄位不存在則丟出錯誤\n",
    "    df[date_col] = pd.to_datetime(df[date_col], errors='coerce')  # 轉為 datetime\n",
    "    df[date_col + '_year'] = df[date_col].dt.year  # 年\n",
    "    df[date_col + '_month'] = df[date_col].dt.month  # 月\n",
    "    df[date_col + '_day'] = df[date_col].dt.day  # 日\n",
    "    if drop:\n",
    "        df = df.drop(columns=[date_col])  # 若需要則移除原始日期欄\n",
    "    return df\n",
    "\n",
    "def simple_encoding(df, cols):  # 簡單的 one-hot 編碼（適用欄位種類少的類別欄）\n",
    "    \"\"\"One-hot encode small-cardinality categorical columns.\n",
    "    Returns a new DataFrame with encoded columns.\n",
    "    \"\"\"\n",
    "    return pd.get_dummies(df, columns=cols, dummy_na=False)  # 回傳編碼後的新 DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a732a659",
   "metadata": {},
   "source": [
    "### Pipeline wrapper\n",
    "A small pipeline that composes the helpers above for repeatable preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "49392b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_preprocessing(input_path, output_path=None, *,  # 將前面 helper 串成一個執行流程\n",
    "                      drop_cols=None,\n",
    "                      fill_strategy=None, fill_value=None,\n",
    "                      type_conversions=None,\n",
    "                      date_cols=None, encode_cols=None):\n",
    "    df = load_csv(input_path)  # 讀取資料\n",
    "    df = clean_column_names(df)  # 標準化欄位名稱\n",
    "    if drop_cols:\n",
    "        df = drop_columns(df, drop_cols)  # 刪除指定欄位\n",
    "    if fill_strategy or fill_value is not None:\n",
    "        df = fill_missing(df, strategy=fill_strategy, value=fill_value)  # 處理遺失值\n",
    "    if type_conversions:\n",
    "        df = convert_types(df, type_conversions)  # 轉換欄位型別\n",
    "    if date_cols:\n",
    "        for d in date_cols:\n",
    "            df = add_datetime_parts(df, d)  # 拆出日期部位\n",
    "    if encode_cols:\n",
    "        df = simple_encoding(df, encode_cols)  # 類別欄位編碼\n",
    "    if output_path is not None:\n",
    "        Path(output_path).parent.mkdir(parents=True, exist_ok=True)  # 確保輸出資料夾存在\n",
    "        df.to_csv(output_path, index=False)  # 寫出清理後的 CSV\n",
    "    return df  # 回傳處理後的 DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b4736134",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example usage cell: edit paths and uncomment to run\n"
     ]
    }
   ],
   "source": [
    "# Example usage (uncomment and set real paths to run)\n",
    "# input_path = 'data/jewelry_sales_data.csv'  # 範例輸入路徑\n",
    "# out = run_preprocessing(input_path, output_path='data/jewelry_cleaned_data.csv',\n",
    "#                     drop_cols=['unnamed: 0'],  # 範例要刪除的欄位\n",
    "#                     fill_strategy='median',  # 使用中位數填補遺失值\n",
    "#                     type_conversions={'transaction_date':'datetime'},  # 欄位型別轉換\n",
    "#                     date_cols=['transaction_date'],  # 要拆解的日期欄位\n",
    "#                     encode_cols=['category'])  # 要進行編碼的類別欄\n",
    "# preview(out)  # 顯示處理後的 DataFrame 預覽\n",
    "print('Example usage cell: edit paths and uncomment to run')  # 提示文字"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0141b60",
   "metadata": {},
   "source": [
    "**Next steps**:\n",
    "- Replace placeholders to match your column names from `01_Data_Preprocessing.py`.\n",
    "- Add any domain-specific cleaning (pricing rules, SKU parsing) as small functions and keep them in their own cells so the Jupyter Book renders them clearly.\n",
    "- If you prefer, move the clean functions into a small `src/preprocessing.py` module and import them in the notebook for brevity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adca43f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gather slide-ready summaries and save to files\n",
    "import json  # 用於輸出 JSON\n",
    "from pathlib import Path  # 已在上方引入，但在函式區域再確認一次\n",
    "\n",
    "\n",
    "def gather_slide_data(input_csv, out_json='results/slide_02_03_data.json', out_md='results/slide_02_03.md'):\n",
    "    \"\"\"Compute a compact set of metrics for Slides 2-3 and write JSON and Markdown outputs.\n",
    "    Relies on helper functions defined earlier in this notebook: `load_csv`, `clean_column_names`.\n",
    "    Adds richer missingness summary and item/customer statistics for jewelry analysis.\n",
    "    \"\"\"\n",
    "    Path('results').mkdir(parents=True, exist_ok=True)  # 確保 results 資料夾存在\n",
    "    df = load_csv(input_csv, low_memory=True)  # 讀取 CSV（low_memory 以節省記憶體）\n",
    "    df = clean_column_names(df)  # 標準化欄位名稱\n",
    "\n",
    "    # If a price column exists and needs scaling the caller may have already scaled;\n",
    "    # do not multiply here unconditionally. (caller may pass scaled file.)\n",
    "\n",
    "    metrics = {}  # 儲存所有統計指標的字典\n",
    "    metrics['rows'] = int(len(df))  # 總列數（總交易量）\n",
    "    metrics['columns'] = df.columns.tolist()  # 欄位清單\n",
    "\n",
    "    # customers\n",
    "    if 'customer_id' in df.columns:\n",
    "        metrics['unique_customers'] = int(df['customer_id'].nunique())  # 不重複客戶數\n",
    "\n",
    "    # date range (pick a column containing \"date\")\n",
    "    date_cols = [c for c in df.columns if 'date' in c]\n",
    "    if date_cols:\n",
    "        dcol = date_cols[0]\n",
    "        dser = pd.to_datetime(df[dcol], errors='coerce')\n",
    "        metrics['date_column'] = dcol\n",
    "        metrics['date_min'] = str(dser.min())\n",
    "        metrics['date_max'] = str(dser.max())\n",
    "\n",
    "    # revenue / price\n",
    "    revenue_candidates = [c for c in df.columns if c.lower() in ('revenue','amount','price','total','sales')]\n",
    "    rcol = None\n",
    "    if revenue_candidates:\n",
    "        rcol = revenue_candidates[0]\n",
    "        metrics['revenue_column'] = rcol\n",
    "        # coerce to numeric for safety\n",
    "        rev = pd.to_numeric(df[rcol], errors='coerce')\n",
    "        metrics['total_revenue'] = float(rev.sum(skipna=True))\n",
    "        metrics['median_order_value'] = float(rev.median(skipna=True))\n",
    "        # richer revenue stats\n",
    "        metrics['revenue_stats'] = {\n",
    "            'mean': float(rev.mean(skipna=True)),\n",
    "            'std': float(rev.std(skipna=True)),\n",
    "            'min': float(rev.min(skipna=True)) if rev.count() else None,\n",
    "            'max': float(rev.max(skipna=True)) if rev.count() else None,\n",
    "        }\n",
    "\n",
    "    # top categories\n",
    "    if 'category' in df.columns:\n",
    "        top = df['category'].value_counts().head(10)\n",
    "        metrics['top_categories'] = top.to_dict()\n",
    "        top.to_csv('results/top_categories_slide_02_03.csv')\n",
    "\n",
    "    # attempt to identify an item/product column for item-level summaries\n",
    "    item_candidates = [c for c in df.columns if any(x in c for x in ('item','product','article','sku','title','name'))]\n",
    "    item_col = item_candidates[0] if item_candidates else None\n",
    "    if item_col:\n",
    "        top_items = df[item_col].value_counts().head(200)\n",
    "        metrics['unique_items'] = int(df[item_col].nunique())\n",
    "        metrics['top_items_by_count'] = top_items.to_dict()\n",
    "        top_items.head(100).to_csv('results/top_items_by_count.csv')\n",
    "\n",
    "    # top customers by revenue (if possible)\n",
    "    if rcol and 'customer_id' in df.columns:\n",
    "        grp = df.groupby('customer_id')[rcol].apply(lambda s: pd.to_numeric(s, errors='coerce').sum(skipna=True))\n",
    "        top_cust = grp.sort_values(ascending=False).head(200)\n",
    "        metrics['top_customers_by_revenue'] = top_cust.to_dict()\n",
    "        top_cust.head(100).to_csv('results/top_customers_by_revenue.csv', header=[rcol])\n",
    "\n",
    "    # missingness: fraction, count, non-null\n",
    "    fraction = (df.isnull().mean()).round(3)\n",
    "    count = df.isnull().sum()\n",
    "    non_null = df.notnull().sum()\n",
    "    metrics['missingness'] = {\n",
    "        'fraction': fraction.to_dict(),\n",
    "        'count': count.to_dict(),\n",
    "        'non_null': non_null.to_dict(),\n",
    "    }\n",
    "\n",
    "    # Jewelry-specific statistics: try to load articles and compute jewelry metrics when possible\n",
    "    jewelry_metrics = {}\n",
    "    articles_path = Path('data') / 'articles.csv'\n",
    "    try:\n",
    "        if articles_path.exists() and 'article_id' in df.columns:\n",
    "            articles_df = load_csv(articles_path)\n",
    "            # normalize name column candidates\n",
    "            cols = [c for c in articles_df.columns]\n",
    "            name_col = None\n",
    "            if 'product_type_name' in cols:\n",
    "                name_col = 'product_type_name'\n",
    "            elif 'product_group_name' in cols:\n",
    "                name_col = 'product_group_name'\n",
    "            # find jewelry articles using name_col if available\n",
    "            jewelry_keywords = ['jewelry', 'jewellery', 'necklace', 'bracelet', 'earring', 'ring', 'pendant', 'charm', 'brooch', 'cufflink']\n",
    "            if name_col:\n",
    "                mask = articles_df[name_col].astype(str).str.lower().str.contains('|'.join(jewelry_keywords), na=False)\n",
    "                jewelry_articles = articles_df[mask]\n",
    "            else:\n",
    "                jewelry_articles = pd.DataFrame(columns=articles_df.columns)\n",
    "\n",
    "            # transactions that match jewelry articles\n",
    "            if not jewelry_articles.empty:\n",
    "                jew_tx = df[df['article_id'].isin(jewelry_articles['article_id'])]\n",
    "                jewelry_metrics['jewelry_transaction_count'] = int(len(jew_tx))\n",
    "                if 'customer_id' in jew_tx.columns:\n",
    "                    jewelry_metrics['jewelry_unique_customers'] = int(jew_tx['customer_id'].nunique())\n",
    "                if rcol and not jew_tx.empty:\n",
    "                    jr = pd.to_numeric(jew_tx[rcol], errors='coerce')\n",
    "                    jewelry_metrics['jewelry_total_revenue'] = float(jr.sum(skipna=True))\n",
    "                    jewelry_metrics['jewelry_median_order_value'] = float(jr.median(skipna=True))\n",
    "                # top jewelry items by count and revenue if item_col present\n",
    "                if item_col and item_col in jew_tx.columns:\n",
    "                    top_j_items = jew_tx[item_col].value_counts().head(50)\n",
    "                    jewelry_metrics['top_jewelry_items_by_count'] = top_j_items.to_dict()\n",
    "                    top_j_items.to_csv('results/top_jewelry_items_by_count.csv')\n",
    "                if rcol and 'customer_id' in jew_tx.columns:\n",
    "                    cust_jrev = jew_tx.groupby('customer_id')[rcol].apply(lambda s: pd.to_numeric(s, errors='coerce').sum(skipna=True))\n",
    "                    jewelry_metrics['top_jewelry_customers_by_revenue'] = cust_jrev.sort_values(ascending=False).head(50).to_dict()\n",
    "    except Exception as e:\n",
    "        # if anything fails, record the error for debugging\n",
    "        jewelry_metrics['error'] = str(e)\n",
    "\n",
    "    if jewelry_metrics:\n",
    "        metrics['jewelry'] = jewelry_metrics\n",
    "\n",
    "    # small sample rows to preview in slides\n",
    "    sample_rows = df.sample(n=min(50, len(df)), random_state=1) if len(df) > 0 else df\n",
    "    sample_rows.head(20).to_csv('results/sample_preview_slide_02_03.csv', index=False)\n",
    "\n",
    "    # write json and markdown\n",
    "    with open(out_json, 'w') as f:\n",
    "        json.dump(metrics, f, indent=2, default=str)\n",
    "\n",
    "    # build markdown summary\n",
    "    md_lines = [\n",
    "        '# Data Foundation & Key Metrics (Slides 2-3)\\\\n',\n",
    "        f'- Rows: {metrics.get(\"rows\")}',\n",
    "    ]\n",
    "    if metrics.get('unique_customers') is not None:\n",
    "        md_lines.append(f'- Unique customers: {metrics.get(\"unique_customers\")}')\n",
    "    if metrics.get('date_column'):\n",
    "        md_lines.append(f'- Date range ({metrics.get(\"date_column\")}): {metrics.get(\"date_min\")} → {metrics.get(\"date_max\")})')\n",
    "    if metrics.get('total_revenue') is not None:\n",
    "        md_lines.append(f'- Total revenue ({metrics.get(\"revenue_column\")}): {metrics.get(\"total_revenue\"): .2f}')\n",
    "        md_lines.append(f'- Median order value: {metrics.get(\"median_order_value\"): .2f}')\n",
    "    if metrics.get('revenue_stats'):\n",
    "        rs = metrics['revenue_stats']\n",
    "        md_lines.append(f'- Revenue mean: {rs.get(\"mean\"): .2f} | std: {rs.get(\"std\"): .2f} | min: {rs.get(\"min\")} | max: {rs.get(\"max\")}')\n",
    "    if metrics.get('unique_items') is not None:\n",
    "        md_lines.append(f'- Unique items: {metrics.get(\"unique_items\")}')\n",
    "\n",
    "    md_lines.append('\\n## Top categories (top 10)')\n",
    "    if 'top_categories' in metrics and metrics['top_categories']:\n",
    "        for k, v in metrics['top_categories'].items():\n",
    "            md_lines.append(f'- {k}: {v}')\n",
    "\n",
    "    md_lines.append('\\n## Top items (by count)')\n",
    "    if 'top_items_by_count' in metrics and metrics['top_items_by_count']:\n",
    "        for k, v in list(metrics['top_items_by_count'].items())[:10]:\n",
    "            md_lines.append(f'- {k}: {v}')\n",
    "\n",
    "    md_lines.append('\\n## Top customers (by revenue)')\n",
    "    if 'top_customers_by_revenue' in metrics and metrics['top_customers_by_revenue']:\n",
    "        for k, v in list(metrics['top_customers_by_revenue'].items())[:10]:\n",
    "            md_lines.append(f'- {k}: {v:.2f}')\n",
    "\n",
    "    # jewelry-specific section\n",
    "    if 'jewelry' in metrics:\n",
    "        jm = metrics['jewelry']\n",
    "        md_lines.append('\\n## Jewelry-specific metrics')\n",
    "        if 'jewelry_transaction_count' in jm:\n",
    "            md_lines.append(f'- Jewelry transactions: {jm.get(\"jewelry_transaction_count\")}')\n",
    "        if 'jewelry_unique_customers' in jm:\n",
    "            md_lines.append(f'- Jewelry unique customers: {jm.get(\"jewelry_unique_customers\")}')\n",
    "        if 'jewelry_total_revenue' in jm:\n",
    "            md_lines.append(f'- Jewelry total revenue: {jm.get(\"jewelry_total_revenue\"): .2f}')\n",
    "        if 'jewelry_median_order_value' in jm:\n",
    "            md_lines.append(f'- Jewelry median order value: {jm.get(\"jewelry_median_order_value\"): .2f}')\n",
    "        if 'top_jewelry_items_by_count' in jm:\n",
    "            md_lines.append('\\nTop jewelry items (by count):')\n",
    "            for k, v in list(jm['top_jewelry_items_by_count'].items())[:10]:\n",
    "                md_lines.append(f'- {k}: {v}')\n",
    "        if 'top_jewelry_customers_by_revenue' in jm:\n",
    "            md_lines.append('\\nTop jewelry customers (by revenue):')\n",
    "            for k, v in list(jm['top_jewelry_customers_by_revenue'].items())[:10]:\n",
    "                md_lines.append(f'- {k}: {v:.2f}')\n",
    "\n",
    "    md_lines.append('\\n## Missingness (fraction / count / non-null)')\n",
    "    miss = metrics.get('missingness', {})\n",
    "    for k, v in list(miss.get('fraction', {}).items())[:10]:\n",
    "        md_lines.append(f'- {k}: fraction={v} count={miss.get(\"count\", {}).get(k, None)} non_null={miss.get(\"non_null\", {}).get(k, None)}')\n",
    "\n",
    "    md_lines.append('\\n## Notes')\n",
    "    md_lines.append('- Missingness and column list saved to JSON.')\n",
    "    md_lines.append('- CSV previews in results/ for top categories, items, and customers.')\n",
    "\n",
    "    with open(out_md, 'w') as f:\n",
    "        f.write('\\n'.join(md_lines))\n",
    "\n",
    "    print('Wrote:', out_json, out_md)\n",
    "    return metrics\n",
    "\n",
    "\n",
    "# Example call (uncomment to run):  # 範例呼叫：把註解拿掉即可執行\n",
    "# gather_slide_data('data/transactions_train_sample.csv')\n",
    "\n",
    "\n",
    "\n",
    "# Adjust the path below if your sample filename differs\n",
    "\n",
    "# sample_path = 'data/transactions_train_sample.csv'\n",
    "# sample_path = '/Users/jzou/Library/Mobile Documents/com~apple~CloudDocs/data/transactions_train_sample.csv'\n",
    "\n",
    "# print('Running gather_slide_data on', sample_path)\n",
    "# metrics = gather_slide_data(sample_path)\n",
    "# print('Done. Metrics keys:', list(metrics.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0dddcf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Top Jewelry Types ---\n",
      "product_type_name\n",
      "Earring        1159\n",
      "Necklace        581\n",
      "Ring            240\n",
      "Hair string     238\n",
      "Bracelet        180\n",
      "Earrings         11\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Jewelry article IDs: 2409 unique items\n",
      "Shape of customers_df: (1371980, 8) | jewelry_buyers: (35592, 8) | all_customers: (1371980, 8)\n",
      "For plotting purpuroses; \n",
      "\n",
      "Customer categories: ['Jewelry Buyers', 'Non-Jewelry Buyers']\n",
      "Customer counts: [35592, 1336388]\n",
      "Saved results/figure1_market_penetration_by_01ipynb.png\n",
      "Saved results/figure2_age_group_comparison.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vf/ny5kp6696qx8jm874dw3bqy80000gn/T/ipykernel_24248/1211472776.py:175: MatplotlibDeprecationWarning: The 'labels' parameter of boxplot() has been renamed 'tick_labels' since Matplotlib 3.9; support for the old name will be dropped in 3.11.\n",
      "  bp = ax.boxplot(box_data, labels=['Jewelry Buyers', 'All Customers'],\n",
      "/var/folders/vf/ny5kp6696qx8jm874dw3bqy80000gn/T/ipykernel_24248/1211472776.py:203: UserWarning: Tight layout not applied. The bottom and top margins cannot be made large enough to accommodate all Axes decorations.\n",
      "  plt.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved results/figure3_age_distribution_boxplot.png\n",
      "Wrote: results/slide_02_03_data.json results/slide_02_03.md\n",
      "Done. Metrics keys: ['rows', 'columns', 'unique_customers', 'revenue_column', 'total_revenue', 'median_order_value', 'revenue_stats', 'unique_items', 'top_items_by_count', 'top_customers_by_revenue', 'missingness', 'jewelry']\n"
     ]
    }
   ],
   "source": [
    "# Integrate figure creation and price-scaling into the notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "navy_blue = '#0A2463'\n",
    "accent_gold = '#D4AF37'\n",
    "white = '#FFFFFF'\n",
    "\n",
    "\n",
    "def scale_price_in_transactions(in_path, out_path, factor=590):\n",
    "    \"\"\"Multiply numeric price-like columns by `factor` and write a new CSV.\"\"\"\n",
    "    df = load_csv(in_path)\n",
    "    # detect candidate price/revenue columns\n",
    "    candidates = [c for c in df.columns if c.lower() in ('revenue','amount','price','total','sales')]\n",
    "    if not candidates:\n",
    "        # try columns that contain 'price' or 'amount'\n",
    "        candidates = [c for c in df.columns if 'price' in c.lower() or 'amount' in c.lower()]\n",
    "    for c in candidates:\n",
    "        df[c] = pd.to_numeric(df[c], errors='coerce') * factor\n",
    "    Path(out_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    df.to_csv(out_path, index=False)\n",
    "    print(f'Scaled {len(candidates)} columns by {factor} and wrote: {out_path}')\n",
    "    return out_path\n",
    "\n",
    "\n",
    "def load_three_figures_data(transactions_path, data_dir='data'):\n",
    "    \"\"\"Load customers, articles, and transactions (transactions_path can be custom).\"\"\"\n",
    "    customers_df = load_csv(Path(data_dir) / 'customers.csv')\n",
    "    articles_df = load_csv(Path(data_dir) / 'articles.csv')\n",
    "    transactions_df = load_csv(transactions_path)\n",
    "\n",
    "    jewelry_keywords = ['jewelry', 'jewellery', 'necklace', 'bracelet', 'earring', 'ring', 'pendant', 'charm', 'brooch', 'cufflink']\n",
    "\n",
    "    if 'product_type_name' in articles_df.columns:\n",
    "        articles_df['is_jewelry'] = articles_df['product_type_name'].astype(str).str.lower().str.contains(\n",
    "            '|'.join(jewelry_keywords), na=False\n",
    "        )\n",
    "    else:\n",
    "        articles_df['is_jewelry'] = False\n",
    "    if 'product_type_name' in articles_df.columns:\n",
    "        print(f'\\n--- Top Jewelry Types ---')\n",
    "        jewelry_types = articles_df[articles_df['is_jewelry']]['product_type_name'].value_counts()\n",
    "        print(jewelry_types)\n",
    "\n",
    "    # Create jewelry articles reference\n",
    "    # 建立珠寶商品參考資料\n",
    "    jewelry_article_ids = set(articles_df[articles_df['is_jewelry']]['article_id'].unique())\n",
    "    print(f'\\nJewelry article IDs: {len(jewelry_article_ids)} unique items')\n",
    "\n",
    "    # Identify transactions that are jewelry purchases\n",
    "    # 識別珠寶購買交易\n",
    "    transactions_df['is_jewelry_purchase'] = transactions_df['article_id'].isin(jewelry_article_ids)\n",
    "    jewelry_transactions = transactions_df[transactions_df['is_jewelry_purchase']]\n",
    "    jewelry_customers = set(jewelry_transactions['customer_id'].unique()) if 'customer_id' in jewelry_transactions.columns else set()\n",
    "\n",
    "    customers_df['is_jewelry_buyer'] = customers_df['customer_id'].isin(jewelry_customers)\n",
    "    customers_df.drop_duplicates(subset=['customer_id'], inplace=True)\n",
    "\n",
    "    jewelry_buyers = customers_df[customers_df['is_jewelry_buyer']]\n",
    "    all_customers = customers_df\n",
    "\n",
    "    articles_df.to_csv(os.path.join(data_dir,'articles_with_jewelry_flag.csv'), index=False)\n",
    "    customers_df.to_csv(os.path.join(data_dir,'customers_with_jewelry_flag.csv'), index=False)\n",
    "    transactions_df.to_csv(os.path.join(data_dir,'transactions_with_jewelry_flag.csv'), index=False)\n",
    "    print(f\"Shape of customers_df: {customers_df.shape} | jewelry_buyers: {jewelry_buyers.shape} | all_customers: {all_customers.shape}\")\n",
    "    return jewelry_buyers, all_customers\n",
    "\n",
    "\n",
    "# Chart functions (adapted from src/create_three_figures.py)\n",
    "def create_market_penetration_chart(jewelry_buyers, all_customers, out_path='results/figure1_market_penetration_by_01ipynb.png'):\n",
    "    fig, ax = plt.subplots(figsize=(8, 8))\n",
    "    fig.patch.set_facecolor(white)\n",
    "\n",
    "    customer_categories = ['Jewelry Buyers', 'Non-Jewelry Buyers']\n",
    "\n",
    "    total_customers = all_customers['customer_id'].nunique()\n",
    "    total_jewelry_buyers = jewelry_buyers['customer_id'].nunique()\n",
    "\n",
    "    customer_counts = [total_jewelry_buyers, total_customers - total_jewelry_buyers]\n",
    "    print(f\"For plotting purpuroses; \\n\\nCustomer categories: {customer_categories}\")\n",
    "    print(f\"Customer counts: {customer_counts}\")\n",
    "    colors_cust = [accent_gold, navy_blue]\n",
    "\n",
    "    wedges, texts, autotexts = ax.pie(\n",
    "        customer_counts, labels=customer_categories, colors=colors_cust,\n",
    "        autopct='%1.1f%%', startangle=90,\n",
    "        wedgeprops=dict(edgecolor='white', linewidth=2),\n",
    "        textprops={'fontsize': 11, 'fontweight': 'bold'}\n",
    "    )\n",
    "    for autotext in autotexts:\n",
    "        autotext.set_color('white')\n",
    "        autotext.set_fontweight('bold')\n",
    "    ax.set_title('Customer Penetration', fontsize=12, fontweight='bold', color=navy_blue, pad=10)\n",
    "\n",
    "    # jewelry_pct = (len(jewelry_buyers) / len(all_customers)) * 100 if len(all_customers) else 0\n",
    "    # non_jewelry_pct = 100 - jewelry_pct\n",
    "    # sizes = [non_jewelry_pct, jewelry_pct]\n",
    "    # colors = [navy_blue, accent_gold]\n",
    "    # labels = ['Non-Jewelry Buyers', 'Jewelry Buyers']\n",
    "    # wedges, texts, autotexts = ax.pie(sizes, colors=colors, labels=labels, \n",
    "    #                                  autopct='%1.1f%%', startangle=90,\n",
    "    #                                  wedgeprops=dict(width=0.5, edgecolor='white', linewidth=2),\n",
    "    #                                  textprops={'fontsize': 14, 'fontweight': 'bold', 'color': navy_blue})\n",
    "    # for autotext in autotexts:\n",
    "    #     autotext.set_color('white')\n",
    "    #     autotext.set_fontsize(14)\n",
    "    #     autotext.set_fontweight('bold')\n",
    "    # ax.set_title('Market Penetration', fontsize=18, fontweight='bold', \n",
    "    #               color=navy_blue, pad=20)\n",
    "    ax.axis('equal')\n",
    "    plt.tight_layout()\n",
    "    Path(out_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(out_path, dpi=300, bbox_inches='tight', facecolor=white)\n",
    "    plt.close()\n",
    "    print(f\"Saved {out_path}\")\n",
    "\n",
    "\n",
    "def create_age_group_comparison_chart(jewelry_buyers, all_customers, out_path='results/figure2_age_group_comparison.png'):\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    fig.patch.set_facecolor(white)\n",
    "\n",
    "    age_bins = [20, 25, 30, 35, 40, 45, 50, 55, 100]\n",
    "    age_labels = ['20-24', '25-29', '30-34', '35-39', '40-44', '45-49', '50-54', '55+']\n",
    "    jewelry_age_dist = pd.cut(jewelry_buyers['age'], bins=age_bins, labels=age_labels, right=False).value_counts().sort_index()\n",
    "    all_age_dist = pd.cut(all_customers['age'], bins=age_bins, labels=age_labels, right=False).value_counts().sort_index()\n",
    "\n",
    "    jewelry_pct = (jewelry_age_dist / len(jewelry_buyers)) * 100 if len(jewelry_buyers) else np.zeros(len(age_labels))\n",
    "    all_pct = (all_age_dist / len(all_customers)) * 100 if len(all_customers) else np.zeros(len(age_labels))\n",
    "\n",
    "    x = np.arange(len(age_labels))\n",
    "    width = 0.35\n",
    "    bars1 = ax.bar(x - width/2, jewelry_pct.values, width, label='Jewelry Buyers', \n",
    "                    color=accent_gold, edgecolor=navy_blue, linewidth=2)\n",
    "    bars2 = ax.bar(x + width/2, all_pct.values, width, label='All Customers', \n",
    "                    color=navy_blue, edgecolor=navy_blue, linewidth=2)\n",
    "    ax.set_xlabel('Age Group', fontsize=14, fontweight='bold', color=navy_blue)\n",
    "    ax.set_ylabel('Percentage (%)', fontsize=14, fontweight='bold', color=navy_blue)\n",
    "    ax.set_title('Age Group Distribution Comparison', fontsize=18, fontweight='bold', \n",
    "                  color=navy_blue, pad=20)\n",
    "    ax.set_xticks(x)\n",
    "    ax.set_xticklabels(age_labels, fontsize=12)\n",
    "    ax.legend(fontsize=12, loc='upper right')\n",
    "    ax.tick_params(axis='both', colors=navy_blue, labelsize=12)\n",
    "    ax.spines['bottom'].set_color(navy_blue)\n",
    "    ax.spines['left'].set_color(navy_blue)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_linewidth(2)\n",
    "    ax.spines['left'].set_linewidth(2)\n",
    "    ax.set_facecolor(white)\n",
    "\n",
    "    for bars in [bars1, bars2]:\n",
    "        for bar in bars:\n",
    "            height = bar.get_height()\n",
    "            ax.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                    f'{height:.1f}%',\n",
    "                    ha='center', va='bottom', fontsize=10, fontweight='bold', \n",
    "                    color=navy_blue)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    Path(out_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(out_path, dpi=300, bbox_inches='tight', facecolor=white)\n",
    "    plt.close()\n",
    "    print(f\"Saved {out_path}\")\n",
    "\n",
    "\n",
    "def create_age_distribution_boxplot(jewelry_buyers, all_customers, out_path='results/figure3_age_distribution_boxplot.png'):\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    fig.patch.set_facecolor(white)\n",
    "\n",
    "    jewelry_mean = jewelry_buyers['age'].mean() if len(jewelry_buyers) else np.nan\n",
    "    all_mean = all_customers['age'].mean() if len(all_customers) else np.nan\n",
    "\n",
    "    box_data = [jewelry_buyers['age'], all_customers['age']]\n",
    "    bp = ax.boxplot(box_data, labels=['Jewelry Buyers', 'All Customers'], \n",
    "                     patch_artist=True, widths=0.6)\n",
    "    for patch in bp['boxes']:\n",
    "        patch.set_facecolor(white)\n",
    "        patch.set_edgecolor(navy_blue)\n",
    "        patch.set_linewidth(3)\n",
    "    for element in ['whiskers', 'fliers', 'medians', 'caps']:\n",
    "        plt.setp(bp[element], color=navy_blue, linewidth=2)\n",
    "    if 'means' in bp:\n",
    "        plt.setp(bp['means'], color=accent_gold, linewidth=2, marker='D', markersize=8)\n",
    "\n",
    "    ax.text(1, jewelry_mean, f'Mean: {jewelry_mean:.1f}' if not np.isnan(jewelry_mean) else 'Mean: N/A', \n",
    "             ha='center', va='bottom', fontsize=12, fontweight='bold', color=accent_gold)\n",
    "    ax.text(2, all_mean, f'Mean: {all_mean:.1f}' if not np.isnan(all_mean) else 'Mean: N/A', \n",
    "             ha='center', va='bottom', fontsize=12, fontweight='bold', color=navy_blue)\n",
    "\n",
    "    ax.set_ylabel('Age', fontsize=14, fontweight='bold', color=navy_blue)\n",
    "    ax.set_title('Age Distribution Comparison', fontsize=18, fontweight='bold', \n",
    "                  color=navy_blue, pad=20)\n",
    "    ax.tick_params(axis='both', colors=navy_blue, labelsize=12)\n",
    "    ax.spines['bottom'].set_color(navy_blue)\n",
    "    ax.spines['left'].set_color(navy_blue)\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    ax.spines['bottom'].set_linewidth(2)\n",
    "    ax.spines['left'].set_linewidth(2)\n",
    "    ax.set_facecolor(white)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    Path(out_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "    plt.savefig(out_path, dpi=300, bbox_inches='tight', facecolor=white)\n",
    "    plt.close()\n",
    "    print(f\"Saved {out_path}\")\n",
    "\n",
    "\n",
    "# Use original (unscaled) data for consistency across notebooks\n",
    "# 使用原始(未縮放)資料以確保跨 notebook 的一致性\n",
    "# orig_sample = 'data/transactions_train_sample.csv'\n",
    "jiacheng_data_folder = '/Users/jzou/Library/Mobile Documents/com~apple~CloudDocs/data'\n",
    "serena_data_folder = 'data'\n",
    "\n",
    "orig_sample = os.path.join(serena_data_folder, 'transactions_train_sample.csv')\n",
    "\n",
    "\n",
    "# load data for figures using original transactions\n",
    "jewelry_buyers, all_customers = load_three_figures_data(orig_sample, data_dir=serena_data_folder)\n",
    "\n",
    "# create figures\n",
    "create_market_penetration_chart(jewelry_buyers, all_customers)\n",
    "create_age_group_comparison_chart(jewelry_buyers, all_customers)\n",
    "create_age_distribution_boxplot(jewelry_buyers, all_customers)\n",
    "\n",
    "# recompute slide metrics on original (unscaled) file for consistency\n",
    "# 在原始檔案上重新計算投影片指標以確保一致性\n",
    "metrics_original = gather_slide_data(orig_sample, out_json='results/slide_02_03_data.json', out_md='results/slide_02_03.md')\n",
    "print('Done. Metrics keys:', list(metrics_original.keys()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20b43d1d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
